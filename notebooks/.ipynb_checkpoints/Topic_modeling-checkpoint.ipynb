{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:34:51.330904Z",
     "start_time": "2019-03-13T21:34:49.953518Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:35:07.556262Z",
     "start_time": "2019-03-13T21:35:07.418438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMOCRATIE_ET_CITOYENNETE.csv\r\n",
      "EVENTS.csv\r\n",
      "LA_FISCALITE_ET_LES_DEPENSES_PUBLIQUES.csv\r\n",
      "LA_TRANSITION_ECOLOGIQUE.csv\r\n",
      "ORGANISATION_DE_LETAT_ET_DES_SERVICES_PUBLICS.csv\r\n",
      "Population_par_departement.csv\r\n",
      "readme.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T21:36:33.200184Z",
     "start_time": "2019-03-13T21:36:30.240324Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/DEMOCRATIE_ET_CITOYENNETE.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:42:42.643755Z",
     "start_time": "2019-03-13T22:42:42.439807Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = (df.iloc[:, -2]+' '+df.iloc[:, -3]+' '+df.iloc[:, -4]+' '+df.iloc[:, -5]).dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:42:51.149078Z",
     "start_time": "2019-03-13T22:42:45.440109Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "no_features = 1000\n",
    "stop_words = ['le', 'la', 'est', 'de', 'qui', 'et', 'se', 'il', 'pour', 'un', 'des', 'une', 'sur', 'ou', 'je', 'les', 'que', 'dans', 'suis', 'sont', 'au', 'en', 'on', 'par', 'ai', 'du', 'ce', 'mais', 'ne', 'pas', 'plus', 'qu', 'être', 'leur', 'aux', 'mon', 'moi', 'me', 'ma', 'son', 'avoir', 'car', 'nous', 'ils', 'etc', 'vous', 'faire', 'si']\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words=stop_words)\n",
    "tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words=stop_words)\n",
    "tf = tf_vectorizer.fit_transform(texts)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:44:17.878640Z",
     "start_time": "2019-03-13T22:42:51.503543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "no_topics = 10\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:44:18.230882Z",
     "start_time": "2019-03-13T22:44:18.203178Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "france français tout ont peut personnes ceux monde\n",
      "Topic 1:\n",
      "quotas langue oui apprentissage française besoins fonction français\n",
      "Topic 2:\n",
      "politique accueil migratoire intégration doit avec européenne niveau\n",
      "Topic 3:\n",
      "pays aider origine développement leurs ces aide développer\n",
      "Topic 4:\n",
      "notre nos valeurs lois respect culture vie société\n",
      "Topic 5:\n",
      "travail logement oui intégration donner accueillir éducation non\n",
      "Topic 6:\n",
      "faut intégrer arrêter accueillir mettre cela aussi donc\n",
      "Topic 7:\n",
      "migrants accueillir économiques accueil non migrant france accepter\n",
      "Topic 8:\n",
      "sais oui rien sujet pense difficile trop pourquoi\n",
      "Topic 9:\n",
      "immigration choisie droit asile trop regroupement familial frontières\n",
      "Topic 0:\n",
      "voir ci dessus main oeuvre réponse accompagnement humanité\n",
      "Topic 1:\n",
      "français france doit ans nationalité française cas personne\n",
      "Topic 2:\n",
      "pays développement aider immigration faut origine contre oui\n",
      "Topic 3:\n",
      "politique immigration doit avec intégration france migratoire cette\n",
      "Topic 4:\n",
      "immigration droit asile pays trop regroupement familial frontières\n",
      "Topic 5:\n",
      "pays accueil migrants ces asile non réfugiés france\n",
      "Topic 6:\n",
      "pays france faut français ont chez ceux ces\n",
      "Topic 7:\n",
      "bien tout non gens accueillir peut sais problème\n",
      "Topic 8:\n",
      "notre nos langue pays accueillir oui valeurs faut\n",
      "Topic 9:\n",
      "oui immigration travail langue besoins intégration formation quotas\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "no_top_words = 8\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:45:27.721030Z",
     "start_time": "2019-03-13T22:45:27.713640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:45:31.499831Z",
     "start_time": "2019-03-13T22:45:28.242161Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:51: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "first_topic = pd.DataFrame(nmf.transform(tfidf)).apply(np.argmax, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:45:32.291405Z",
     "start_time": "2019-03-13T22:45:32.281615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6727\n",
       "1    2757\n",
       "2    4177\n",
       "3    2462\n",
       "4    1981\n",
       "5    1652\n",
       "6    1475\n",
       "7    1861\n",
       "8     738\n",
       "9    2920\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_topic.groupby(first_topic.values).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T22:45:35.110461Z",
     "start_time": "2019-03-13T22:45:34.993464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:51: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     2575\n",
       "1    16273\n",
       "2    20422\n",
       "3    20273\n",
       "4    19584\n",
       "5    21747\n",
       "6    18007\n",
       "7     2370\n",
       "8      285\n",
       "9    20377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(nmf.transform(tfidf)).apply(np.argmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
